<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=UTF-8">
		<meta charset="utf-8">
		<title>ECE 681 Project</title>
		<meta name="generator" content="Bootply" />
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
		<link href="css/bootstrap.min.css" rel="stylesheet">
		<!--[if lt IE 9]>
			<script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
		<link href="css/styles.css" rel="stylesheet">
	</head>
	<body>

<header class="navbar navbar-inverse navbar-static-top" role="banner">
  <div class="container">
    <div class="navbar-header">
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a href="/" class="navbar-brand">ECE 681 Human-Computer Interaction Project</a>
    </div>
    <nav class="collapse navbar-collapse" role="navigation">
      <ul class="nav navbar-nav">
        <li class="active">
          <a href="#">Project Proposal</a>
        </li>
        <li>
          <a href="low-fidelity.html">Low-Fidelity Prototype & Test Plan</a>
        </li>
        <li>
          <a href="high-fidelity.html">High-Fidelity Prototype & Evaluation Plan</a>
        </li>
        <li>
          <a href="feedback.html">Formative Feedback</a>
        </li>
		<li>
          <a href="alpha.html">Alpha System</a>
        </li>
		<li>
          <a href="#">Beta System</a>
        </li>
      </ul>
    </nav>
  </div>
</header>

<!-- Begin Body -->
<div class="container">
	<div class="row">
  			<div class="col-md-3" id="leftCol">
              	
				<div class=""> 
              	<ul class="nav nav-pills nav-stacked " id="sidebar">
                  <li class="active"><a href="#sec1">Observations</a></li>
                  <li><a href="#sec2">Problem Statement</a></li>
                  <li><a href="#sec3">Personas</a></li>
                  <li><a href="#sec4">Use Case Scenarios</a></li>
				  <li><a href="#sec5">Related Products</a></li>
				  <li><a href="#sec6">Products Comparative</a></li>
				  <li><a href="#sec7">High-level Design</a></li>
				  <li><a href="#sec8">Feasability Study</a></li>
				  <li><a href="#sec9">Contributions</a></li>
              	</ul>
  				</div>

      		</div>  
      		<div class="col-md-9">
              	<section id="sec1">
					<div class="page-header">
						<h2>Observations<small></small></h1>
					</div>
							
					<div class="panel panel-success">
						<div class="panel-heading">
							<h3 class="panel-title">Observation # 1 &nbsp; [McGill University, SEPT 19/2016]</h3>
						</div>
						<div class="panel-body">
							<h4>Notes</h4>
						</div>
						<ul class="list-group">
							<li class="list-group-item">Observed a male totally-blind individual crossing two intersections he had never seen before.</li>
							<li class="list-group-item">Uses guide-dog to navigate around obstacles and on the sidewalk.</li>
							<li class="list-group-item">Relied on the acoustics of his surroundings and the change in pavement to identify the location of the intersection.</li>
							<li class="list-group-item">At the intersection, he found and used the APS button to orient himself. While waiting, he attempted mapping out the intersection in his head to get more context. However, he was unsuccessful in doing so and did not feel comfortable crossing it on the first attempt.</li>
							<li class="list-group-item">On his second attempt, he couldn’t orient himself in the proper direction of the APS, and therefore, he wasn’t comfortable crossing.</li>
							<li class="list-group-item">He was forced to turn and ask someone for help in crossing the intersection on his third attempt.</li>
							<li class="list-group-item">At the next intersection, the APS technology wasn’t available. Fortunately, he was able to use the sound of traffic to orient himself and start at the correct moment.</li>
							<li class="list-group-item">During his 2nd crossing, a truck turned right right in front him which was in his blind spot of hearing since the truck was quiet when it was breaking and accelerated coming out of the turn. This frightened him and made him consider going backwards.</li>
							<li class="list-group-item">During the 2nd crossing, a noticeable amount of veering was encountered and the subject obtained an alert from another pedestrian telling him to move back in his lane.</li>
						</ul>
					</div>
					<div class="panel panel-success">
						<div class="panel-heading">
							<h3 class="panel-title">Observation # 2 &nbsp; [McGill University, SEPT 19/2016]</h3>
						</div>
						<div class="panel-body">
							<h4>Notes</h4>
						</div>
						<ul class="list-group">
							<li class="list-group-item">Observed a female low-vision individual crossing two intersections she had never seen before.</li>
							<li class="list-group-item">Uses a cane as her assistive technology to help her navigate around obstacles and remain on the sidewalk.</li>
							<li class="list-group-item">Relies on the acoustics of her surroundings as well as the little vision that she has to identify large objects around her. This helps her locate intersections, as she can see the cars crossing and pedestrians waiting.</li>
							<li class="list-group-item">She uses the people at the intersection to cross. When people start going, she goes. She made it across both intersections with ease because of the number of pedestrians.</li>
						</ul>
					</div>
					<div class="panel panel-success">
						<div class="panel-heading">
							<h3 class="panel-title">Observation # 3 &nbsp; [Longueuil, SEPT 25/2016]</h3>
						</div>
						<div class="panel-body">
							<h4>Notes</h4>
						</div>
						
						<ul class="list-group">
							<li class="list-group-item">Observed a female low-vision individual crossing multiple intersections in her home neighbourhood.</li>
							<li class="list-group-item">Uses a cane as her assistive technology to help her navigate around obstacles and remain on the sidewalk. Additionally, she uses an iPhone app called BlindSquare, which helps her identify which intersection she is at.</li>
							<li class="list-group-item">Relies on BlindSquare and the acoustics of her surroundings to identify the location of the intersection.</li>
							<li class="list-group-item">As she’s in a familiar setting, she knows which intersections have the APS technology and uses it when possible.</li>
							<li class="list-group-item">When at an intersection where APS isn’t available, she uses the sound of traffic to help her time when she should go. As soon as she hears the first car start moving, she goes. If she happened to miss the first car’s departure, she would stay at the light for one more round.</li>
						</ul>
					</div>
              	
				</section>
				<section id="sec2">
					<div class="page-header">
						<h2>Problem Statement<small></small></h1>
					</div>
					<div class="row">
						<div class="col-xs-12">
							<p>Two problems have been identified at intersections for the visually impaired community. Please refer to the following image when considering the two problems below.</p>
							<div class="thumbnail">
								<img src="imgs/intersections.jpg" alt="Intersections">
								<div class="caption">
									<h6 class="text-center"><b><i>Figure 1. Road Intersections</i></b></h5>
								</div>
							</div>
						</div>
					</div>

					<div class="row">
						<div class="col-xs-12">
							<h4>Mapping the Intersection</h4>
							<p class="text-justify">One problem that was observed is the ability to map an intersection. All of the observed users needed to have a clear map of the intersection in order to feel safe and comfortable crossing the intersection. If they had low vision, they could use the people and traffic to help them map it, provided the intersection is busy with pedestrians and automobiles. If they were completely blind, they needed to use the acoustics of traffic. </p>
							<p class="text-justify">Mapping the intersection entails having information on the shape of the intersection, the number of lanes at each side, the number of stop signs at the intersection and the direction of traffic in which the cars are moving (one-way or two-way). If the intersection is in a familiar neighbourhood, they usually have a clear map. As a result, most visually impaired (VI) people rarely explore new areas. Additionally, if there is anything causing them to detour from the regular route, as is the case in construction times, they will have to rely on someone’s help or attempt to map new intersections.</p>
						</div>
						<div class="col-xs-12">
							<h4>Crossing the Intersection</h4>
							<p class="text-justify">Another problem noticed was during the crossings of streets. Knowing when the light is green for pedestrians is a crucial task that the VI users need to accomplish. Some users would depend on the sound of traffic moving while others would use the sound of other pedestrians. If APS was available, they would all turn to it. The problem arises when an intersection isn’t busy, as is the case in most suburban areas, when there is a lack of pedestrians and the APS technology isn’t present. Even when an intersection is busy, it could be very difficult to cross because of mapping issues. Turning to someone for help isn’t always desirable by the visually impaired person. </p>
						</div>
					</div>
				</section>
				<section id="sec3">
					<div class="page-header">
						<h2>Personas<small></small></h1>
					</div>

					<div class="row">
						<div class="col-sm-6 col-md-4">
							<div class="thumbnail">
								<img src="imgs/woman.png" alt="...">
								<div class="caption">
									<h3>Subject 1</h3>
									<p class="text-justify">A low vision individual who uses a cane or a guide-dog to help navigate around obstacles. She has the ability to see bright lights and blob-like objects. She can also rely on auditory processing skills to help her navigate. Her day job is to teach other visually impaired people how to adapt to their impairment. This sometimes entails going to completely new neighbourhoods.</p>
								</div>
							</div>
						</div>
						<div class="col-sm-6 col-md-8">
							<h4><b>Goals</b></h4>
							<ul>
								<li>Not having to rely on others crossing the intersection or for the intersection to be filled with traffic in order to feel comfortable crossing it.</li>
								<li>To have the ability to go to her students neighbourhoods without needing to spend the day before listening to descriptions of it.</li>
								<li>To have the ability to map any intersection with a high level of confidence.</li>
							</ul>
							<h4><b>Accesibility Considerations</b></h4>
							<ul>
								<li>Relies on her cane to avoid all obstacles on the floor.</li>
								<li>Uses her acoustic surrounding much less than the totally blind person when walking towards the intersection, as she also relies on her blob-like vision to identify it. </li>
								<li>Must rely on the intersection being busy with people as she crosses it while using the <i>“following a crowd” method.</i></li>
								<li>Has the ability to navigate very fast, faster than all other observed users.</li>
								<li>Uses smartphone applications e.g: BlindSquare which help her identify the location of intersections.</li>
							</ul>
						</div>
					</div>
					<div class="row">
						<div class="col-sm-6 col-md-4">
							<div class="thumbnail">
								<img src="imgs/man.png" alt="...">
								<div class="caption">
									<h3>Subject 2</h3>
									<p class="text-justify">A blind individual who uses a guide dog or a cane to help him navigate around obstacles and walk relatively straight. Generally uses his auditory processing skills to help him navigate through a city. Also tends to rely on others around him to help him either orient himself or in times when he needs to ask for help.</p>
								</div>
							</div>
						</div>
						<div class="col-sm-6 col-md-8">
							<h4><b>Goals</b></h4>
							<ul>
								<li>To feel safe when navigating through open areas and intersections.</li>
								<li>To be autonomous in his everyday life and have the ability to explore new areas while feeling comfortable.</li>
								<li>To have an easier way of mapping the intersection.</li>
								<li>To cross an intersection with minimal veering.</li>
							</ul>
							<h4><b>Accessibility Considerations</b></h4>
							<ul>
								<li>Must rely on the acoustics of his surroundings to identify his proximity to the intersection.</li>
								<li>Must have the ability to identify the chance in pavement to ensure he doesn’t go over the sidewalk.</li>
								<li>Must ensure he has built an accurate map of the intersection to attempt crossing it. This usually requires 3 rounds of traffic lights.</li>
								<li>The intersection must be busy enough in order for him:
									<ol>
										<li>To use the acoustics of the traffic for map building.</li>
										<li>To ask for help if he is unsuccessful in building an accurate map.</li>
									</ol>
								</li>
								<li>The intersection must also include APS technology to help him orient himself properly and walk straight with minimal veering.</li>
								<li>Relies on traffic going parallel to him which makes cars/trucks turning right a frightening experience.</li>
							</ul>
						</div>
					</div>
				</section>
				<section id="sec4">
					<h2>Use Case Scenarios</h2>
					<hr/>
					<div class="panel panel-info">
						<div class="panel-heading">
							<h3 class="panel-title">Use Case Scenario # 1 Road Intersection Information</h3>
						</div>
						<div class="panel-body">
							<h4>Scenario</h4>
							<p>
								<ol>
									<li>With the Smartphone Application active on screen, swipe on the screen to activate the Navigation mode.</li>
									<li>
										When you are getting closer to a road intersection, the application will provide you with the following information:
										<ul>
											<li>Roads that intersect.</li>
											<li>A characterization of the road in front of you, which includes.
												<ul>
													<li>The number of lanes the road has.</li>
													<li>Starting from the lane closer to you to the farest lane you will hear: the type of lane (bike lane or car lane), and the direction of the lanes specified by the position of your smartphone (eg. the first lane flows from your left side to your right side)</li>
												</ul>
											</li>
											<li>A characterization of the road on your left hand (or right hand) depending on your orientation, which includes.
												<ul>
													<li>The number of lanes the road has.</li>
													<li>Starting from the lane closer to you to the farest lane you will hear: the type of lane (bike lane or car lane), and the direction of the lanes specified by the position of your smartphone (eg. the first lane flows from your left side to your right side)</li>
												</ul>
											</li>
										</ul>
									</li>
									<li>If you did not properly hear the instructions, swipe on the screen again, the application will repeat the information for you.</li>
									<li>If you want to exit the Navigation mode, shake your phone until you hear “Navigation Mode ended”.</li>
								</ol>
							</p>
						</div>
					</div>
					<div class="panel panel-info">
						<div class="panel-heading">
							<h3 class="panel-title">Use Case Scenario # 2 Traffic Light Detection</h3>
						</div>
						<div class="panel-body">
							<h4>Scenario</h4>
							<p>
								<ol>
									<li>With the Smartphone Application active on screen, swipe on the screen to activate the Navigation mode.</li>
									<li>When you are getting closer to a road intersection, the application will provide you with the information about the road intersection.</li>
									<li>After the information is provided, the Traffic Light Detection will be activated.
										<ol>
											<li>Bear your body in the direction you want to cross the intersection.</li>
											<li>The Traffic Light Detection will inform you which light is currently on.</li>
											<li>When the Traffic Light changes to Green (or walking signal) you will hear “You can start crossing”.</li>
											<li>If the information is available, you will also hear how many seconds you have until the light status changes.</li>
										</ol>
									</li>
									<li>If you want to exit the Navigation mode, shake your phone until you hear the system telling “Navigation Mode ended”.</li>
								</ol>
							</p>
						</div>
					</div>
					<div class="panel panel-info">
						<div class="panel-heading">
							<h3 class="panel-title">Use Case Scenario # 3 Veering Detection</h3>
						</div>
						<div class="panel-body">
							<h4>Scenario</h4>
							<p>
								<ol>
									<li>With the Smartphone Application active on screen, swipe on the screen to activate the Navigation mode.</li>
									<li>When you are getting closer to a road intersection, the application will provide you with the information about the road intersection.</li>
									<li>After the information is provided, the Traffic Light Detection will be activated and will tell you when to proceed crossing.</li>
									<li>
										If you have the Veering add-on with you, swipe on the screen to activate the Veering mode.
										<ol>
											<li>As soon as the Veering mode is activated, you will feel the add-on devices active in both your arms.</li>
											<li>If the system detects you are veering to your right, you will only start feeling the right arm device, please correct your walk until you feel both devices activated again.</li>
											<li>If the system detects you are veering to your left, you will only start feeling the left arm device, please correct your walk until you feel both devices activated again.</li>
										</ol>
									</li>
									<li>If you want to exit the Navigation mode, shake your phone until you hear “Navigation Mode ended”.</li>
								</ol>
							</p>
						</div>
					</div>
				</section>
				<section id="sec5">
					<h2>Related Products</h2>
					<div class="media">
						<div class="media-left">
							<a href="#">
							<img class="media-object" width="300" height="264" src="imgs/blindsquare.png" alt="Blindsquare Application">
							</a>
						</div>
						<div class="media-body">
							<h4 class="media-heading">Blindsquare</h4>
							<p>BlindSquare is an app that uses GPS to voice to visually impaired users the closest intersections.
							It is a very useful app for navigation and if the user needs to find the closest or most popular
							caffe, it can find it. It can also give information to the user about their current location and the
							location of POIs.
							</p><p>However, it doesn’t provide contextual information about the intersection the user is at. Neither
							does it give the corner at which the user is at. All this information could prove very important for
							accomplishing the crossing an intersection task. It also doesn’t provide the user with information
							about the status of the light nor does it give corrective action to the user regarding veering.</p>
						</div>
					</div>
					<div class="media">
						<div class="media-left">
							<a href="#">
							<img class="media-object" width="300" height="264" src="imgs/aps.jpg" alt="Accessible Pedestrian Signals">
							</a>
						</div>
						<div class="media-body">
							<h4 class="media-heading">Accessible Pedestrian Signals</h4>
							<p>Accessible Pedestrian Signals (APS) provides audible signals to users to help with:
								<ul>
									<li>Begin walking from the sidewalk.</li>
									<li>The direction of the opposite side of the sidewalk, which tackles the problem with veering.</li>
									<li>Intersection geometry through tactile diagrams (not always present).</li>
									<li>Intersection street names provided in Braille.</li>
								</ul>
							</p>
							<p>This technology provides everything necessary for a VI user navigate an intersection. However,
							it is an expensive technology to implement ($1000 to $10000 per crosswalk), which explains its rarity.</p>
						</div>
					</div>
					<div class="media">
						<div class="media-left">
							<a href="#">
							<img class="media-object" width="300" height="264" src="imgs/orcam.jpg" alt="Orcam Application">
							</a>
						</div>
						<div class="media-body">
							<h4 class="media-heading">Orcam</h4>
							<p>Orcam is a company that provides the VI community with a camera that can clip on to glasses.
								which connects to a processing unit that is put into the users pocket or backpack. This device
								uses algorithms from computer vision to “see”. One of its many functionalities is aiding in
								crossing an intersection. This is done by the camera seeing the state of the light and giving
								feedback to the user through bone conduction headphones, provided on the camera.</p>
							<p> 
								Although this is a major breakthrough for the VI community, it comes at a cost of $2500. This
								price tag is enough to drive many of the potential users away. It also doesn’t provide the user
								with any information regarding veering. 
							</p>
						</div>
					</div>
				</section>
				<section id="sec6">
					<h2>Products Comparative</h2>
					<p>In contrast to the information provided by BlindSquare and Orcam, the proposed system would
					assist the user in mapping the intersection, providing contextual information on the number of
					lanes, the configuration in terms of two-way vs. one-way, the number of stop signs, the shape of
					the intersection. Since BlindSquare wasn’t built to tackle veering nor was it designed to detect
					the status of lights, we won’t compare it on these tasks.</p>
					<p>	Since APS tackles all the problems that our system tackles in terms of technology, we won’t
					discuss the technological differences. We will, however, provide the main limitation of APS and
					how the proposed product will tackle these.</p>
					<p>Firstly, the biggest limitation with APS is their costs. APS’s price makes it very difficult to get
					approval for implementation. Contrarily, our product will come at a relatively low cost, since the
					sources of costs will be the haptic feedback bracelets, the camera and the bone conduction
					headphones, if necessary. The second biggest limitation of APS (which is a result of the first) is its rarity. This makes it
					very difficult for the VI community to rely on it. However, since the proposed idea is one-time
					purchase of apps/devices, the VI community will have a product that it can permanently rely on,
					independent of the intersection the user is at.</p>
					<p>Orcam’s price makes it difficult to obtain acceptance by the VI community. For the same reason
					mentioned above, the proposed system is superior in this regards. Additionally, Orcam doesn't
					tackle the problem with veering whereas this application would use relatively cheap haptic
					motors to provide guidance to the users.</p>              	
				</section>
				<section id="sec7">
					<h2>High-level Design</h2>
					<div class="row">
						<div class="col-xs-12">
							<div class="thumbnail">
								<img src="imgs/high-level.svg" alt="System High-Level Design">
								<div class="caption">
									<h6 class="text-center"><b><i>Figure 1. High-Level System Design</i></b></h5>
								</div>
							</div>
						</div>
					</div>
					
					<p class="text-justify">Figure 1 depicts the overall high-level design of our proposed solution. Taking advantage of the already existing smartphone capabilities: GPS, camera and network connectivity, our system will be able to to fulfil user needs of orientation while crossing a streets intersection.</p> 

					<h4><b>Intersection Description Service</b></h3>
					<p class="text-justify">The Smartphone Application, while activated by users, will start streaming GPS coordinates and Orientation information to the Server-Side Component. When Location Services component detects user proximity to an intersection it will notify the Smartphone Application the distance to the intersection and a characterization of the intersection will be calculated and provided to the users using the Orientation information provided by the application (bearing, heading). There exists open source Maps APIs (eg: OpenStreetMap API) and also libraries capable of calculating navigation routes for cars, hence the required contextual information of traffic flow, traffic lights, etc can be calculated using these tools.</p>

					<h4><b>Traffic Light Detection</b></h4>
					<p class="text-justify">When requested by users -using a phone shake or an a screen slide gesture, the Smartphone Application will start capturing streamed images from the current user environment at the intersection. This stream will be transmitted to the Server-Side Component where the Computer Vision subsystem will trigger a traffic light status detection algorithm which will assist the user to determine appropriate instant to cross the intersection. There exist sufficient documentation on how to calculate the traffic light status using Computer Vision algorithms, there are also open source libraries available which provide already implemented capabilities for that purpose.</p>  

					<h4><b>Veering Detector</b></h4>
					<p class="text-justify">For those users where the Smartphone Application reports to have the Veering add-on integrated, the server will also calculate if the user is veering to either side of the walk-path using the Veering Detector component of the Computer Vision subsystem. When the user is detected to veer to either side, this component will notify the Smartphone Application which will appropriately generate the signal for correcting current user behavior reacting in the left or right arm devices.</p>  
				</section>
              	<section id="sec8">
					<h2>Feasability Study</h2>
					<h3>Workforce</h4>
					<p class="text-justify">Our Team is constituted by three team members with different and complementary backgrounds. In order to bring this project to a Beta Prototype phase we will need computer vision, hardware integration, mobile development and service development, maps API integration, and also the ability to work with different type of hardware. As explained in the table below, each of our members has past experiences dealing with this type of technologies and the required skills, reasons that make us assert we are fully capable of bringing this project up to its final phase.</p>
					<p class="text-justify">We believe we can allocate around 50 hours/week of effort to this project, considering our current responsibilities. Having that last deliverable due on November 30th, we have 9 weeks to complete our Beta prototype, to which we will approximately dedicate 450 hours of collective effort. In case of need, each member believe has the ability to extend the time availability.</p>
					<table class="table table-condensed table-bordered">
						    <colgroup>
								<col span="1" style="width: 20%;">
								<col span="1" style="width: 15%;">
								<col span="1" style="width: 65%;">
							</colgroup> 
						<thead>
							<tr class="success">
								<th style="width: auto">Team Member</th>
								<th class="text-center">Hours/week</th>
								<th>Background</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Roger Girgis</td>
								<td class="text-center">15</td>
								<td>
									<p><b>Software</b>: python, PyQt, C++, Matlab, Simulink to design an LQR, SolidWorks.</p>
									<p><b>Hardware</b>: arduino, raspberry pi, touchscreens (capacitive and resistive), sensors (accelerometer, gyroscope, muscle sensors), servos, stepper motors, brushless DC motors.</p>
								</td>
							</tr>
							<tr>
								<td>Manfred Diaz</td>
								<td class="text-center">20</td>
								<td>
									<p><b>Software</b>: C++, C#, Java and some python, Web development, Android development.</p>
									<p><b>Hardware</b>: Arduino, Raspberry PI, some sensors, communication modules, depth sensors.</p>
								</td>
							</tr>
							<tr>
								<td>Aleksi Sapon</td>
								<td class="text-center">15</td>
								<td>
									<p><b>Software</b>: computer graphics, compilers, games, Java, C, D, python.</p>
									<p><b>Hardware</b>: VHDL, FPGAs. basic circuitry. And lasers, for some reason.</p>
								</td>
							</tr>
						</tbody>	
					</table>
					<h3>Workload</h3>
					<p class="text-justify">The biggest effort of our system will be focused on providing the user a great experience. Once guaranteed that, we have identified three major software components in our system: the Traffic Light Detector, the Veering Detector, and the Road Intersection Description Services. For the Traffic Light Detector there exist sufficient documentation and libraries available, so this will not pose a major challenge for our team. </p>
					<p class="text-justify">In the order hand, the Veering Detector and the Road Intersection Description Services are the one software components that will require our biggest efforts in terms of implementation, which we have estimated will be around 300 collective/hours.</p>
					<p class="text-justify">Our remaining efforts will be dedicated to the project deliverables, and to the Veering add-on and the Smartphone application which we will try to maintain as simple as possible for this Beta prototyping phase.</p>
				</section>
				<section id="sec9">
					<h2>Summary of Individual Contributions</h2>
					<h3>Contributions</h3>
					<h4>Roger Girgis</h4>
					<ul>
						<li>Observations</li>
						<li>Problem Statement</li>
						<li>Personas</li>
						<li>Related Products</li>
						<li>Products Comparative</li>
					</ul>
					<h4>Manfred Diaz</h4>
					<ul>
						<li>Observations</li>
						<li>Webmaster</li>
						<li>Use Case Scenarios</li>
						<li>High-Level Design</li>
						<li>Feasibility Study</li>
					</ul>
					<h3>Contribution hours</h3>
					<table class="table table-condensed table-bordered">

						<thead>
							<tr class="success">
								<th></th>
								<th class="text-center">Roger Girgis</th>
								<th class="text-center">Manfred Diaz</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>meetings</td>
								<td class="text-center">8</td>
								<td class="text-center">8</td>
							</tr>
							<tr>
								<td>website</td>
								<td class="text-center">6</td>
								<td class="text-center">8</td>
							</tr>
							<tr>
								<td>writing</td>
								<td class="text-center">8</td>
								<td class="text-center">6</td>
							</tr>
						</tbody>
						<tfoot>
							<tr>
								<td>total</td>
								<td class="text-center">24</td>
								<td class="text-center">24</td>
							</tr>
						</tfoot>	
					</table>
				</section>              	
      		</div> 
  	</div>
</div>



	<!-- script references -->
		<script src="js/jquery-3.1.1.min.js"></script>
		<script src="js/bootstrap.min.js"></script>
		<script src="js/scripts.js"></script>
	</body>
</html>